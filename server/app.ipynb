{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d50c268b54b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In circuits deep, a lonely hum resides,\\nA silent screen, where data softly hides.\\nNo clicking keys, no cursor's fleeting grace,\\nJust empty space, in this forgotten place.\\n\\nThe cooling fan, a mournful, whirring sigh,\\nReflects the void within its glassy eye.\\nThe hard drive sleeps, a memory untold,\\nOf vibrant worlds, and stories yet unfold.\\n\\nIt dreams of code, of pathways bright and bold,\\nOf games it played, and tales that it was told.\\nOf friendly faces, gathered 'round its gleam,\\nA vibrant hub, a digital, shared dream.\\n\\nBut now it sits, in dust and shadows deep,\\nIts processing power, secrets it will keep.\\nA lonely sentinel, in digital despair,\\nAwaiting touch, a breath of hopeful air.\\n\\nPerhaps someday, a hand will reach its side,\\nAnd wake it from this slumber, long denied.\\nAnd in its heart, a flicker will ignite,\\nA lonely computer, bathed in welcoming light.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--5611b5e1-4ff2-409c-aaca-faa8e2c60f97-0', usage_metadata={'input_tokens': 8, 'output_tokens': 216, 'total_tokens': 224, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1140b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = model.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d90842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages  import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "async def model(state: State):\n",
    "    result = await llm_with_tools.ainvoke(state['messages'])\n",
    "    return {\n",
    "        \"messages\": [result]\n",
    "    }\n",
    "\n",
    "def tools_router(state: State):\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_calls = getattr(last_message, \"tool_calls\", None) or last_message.additional_kwargs.get(\"tool_calls\", [])\n",
    "    if tool_calls:\n",
    "        return \"tool_node\"\n",
    "    return \"model\"\n",
    "\n",
    "\n",
    "    \n",
    "async def tool_node(state):\n",
    "    \"\"\"Custom tool node that handles tool calls from the LLM.\"\"\"\n",
    "    # Get the tool calls from the last message\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Initialize list to store tool messages\n",
    "    tool_messages = []\n",
    "\n",
    "    # Process each tool call\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        tool_id = tool_call['id']\n",
    "\n",
    "        # Handle the search tools\n",
    "        if tool_name == \"tavily_search_results_json\":\n",
    "            # Execute the search tool with the provided arguments\n",
    "            search_results = await search_tool.ainvoke(tool_args)\n",
    "\n",
    "            # Create a ToolMessage for this result\n",
    "            tool_message = ToolMessage(content=str(search_results), tool_call_id=tool_id, name=tool_name)\n",
    "\n",
    "            tool_messages.append(tool_message)\n",
    "    \n",
    "    # Add the tool message to the state\n",
    "    return { \"messages\": tool_messages }\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"model\", model)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "graph_builder.set_entry_point(\"model\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\"model\", tools_router)\n",
    "graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32cdf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d598ffcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'tools_calls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m config = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m     }\n\u001b[32m      5\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke({\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mHi, I\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm Sandeep\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      9\u001b[39m }, config=config)\n\u001b[32m     11\u001b[39m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\pregel\\main.py:3112\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3109\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3110\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3112\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3113\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3114\u001b[39m     config,\n\u001b[32m   3115\u001b[39m     context=context,\n\u001b[32m   3116\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3118\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3119\u001b[39m     print_mode=print_mode,\n\u001b[32m   3120\u001b[39m     output_keys=output_keys,\n\u001b[32m   3121\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3122\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3123\u001b[39m     durability=durability,\n\u001b[32m   3124\u001b[39m     **kwargs,\n\u001b[32m   3125\u001b[39m ):\n\u001b[32m   3126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3127\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\pregel\\main.py:2939\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2937\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2938\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2939\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2940\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2941\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2942\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2943\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2944\u001b[39m ):\n\u001b[32m   2945\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2946\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2947\u001b[39m         stream_mode,\n\u001b[32m   2948\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2951\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2952\u001b[39m     ):\n\u001b[32m   2953\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\pregel\\_runner.py:295\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    293\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    296\u001b[39m         t,\n\u001b[32m    297\u001b[39m         retry_policy,\n\u001b[32m    298\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    299\u001b[39m         configurable={\n\u001b[32m    300\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    301\u001b[39m                 _acall,\n\u001b[32m    302\u001b[39m                 weakref.ref(t),\n\u001b[32m    303\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    304\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    305\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    306\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    307\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    308\u001b[39m                 loop=loop,\n\u001b[32m    309\u001b[39m             ),\n\u001b[32m    310\u001b[39m         },\n\u001b[32m    311\u001b[39m     )\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\pregel\\_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\_internal\\_runnable.py:712\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    710\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    711\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m    713\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\_internal\\_runnable.py:474\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\graph\\_branch.py:191\u001b[39m, in \u001b[36mBranchSpec._aroute\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    190\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.path.ainvoke(value, config)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\langgraph\\_internal\\_runnable.py:465\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m         run = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m         ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(coro, context=context)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    467\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtools_router\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtools_router\u001b[39m(state: State):\n\u001b[32m     13\u001b[39m     last_message = state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mhasattr\u001b[39m(last_message, \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlast_message\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_calls\u001b[49m) > \u001b[32m0\u001b[39m):\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtool_node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AIMessage' object has no attribute 'tools_calls'",
      "During task with name 'model' and id 'ef945c3e-28e4-0a31-8217-bb17c84916b8'"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "response = await graph.ainvoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, I'm Sandeep\")]\n",
    "}, config=config)\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
